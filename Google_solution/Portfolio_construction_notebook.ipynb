{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Statistics and machine learning\n",
    "from statsmodels.tsa.api import adfuller\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture as GM \n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import linregress\n",
    "import scipy.optimize as sco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>P/E</th>\n",
       "      <th>EPS</th>\n",
       "      <th>MarketCap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>23.17</td>\n",
       "      <td>8.16</td>\n",
       "      <td>112.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABT</td>\n",
       "      <td>48.03</td>\n",
       "      <td>0.94</td>\n",
       "      <td>77.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>17.55</td>\n",
       "      <td>3.63</td>\n",
       "      <td>101.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACN</td>\n",
       "      <td>18.37</td>\n",
       "      <td>6.76</td>\n",
       "      <td>77.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATVI</td>\n",
       "      <td>37.55</td>\n",
       "      <td>1.28</td>\n",
       "      <td>36.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol    P/E   EPS  MarketCap\n",
       "0    MMM  23.17  8.16     112.74\n",
       "1    ABT  48.03  0.94      77.76\n",
       "2   ABBV  17.55  3.63     101.52\n",
       "3    ACN  18.37  6.76      77.29\n",
       "4   ATVI  37.55  1.28      36.13"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data from Excel spreadsheet\n",
    "fundamental_data = pd.ExcelFile('SPO_Data.xlsx')\n",
    "\n",
    "# Identifying the sheet that will be used. \n",
    "features = fundamental_data.parse('Fundamentals')\n",
    "features = features.drop('Unnamed: 0', axis = 1)\n",
    "\n",
    "# Drop column Name as it is redundant because we already have the symbol\n",
    "features = features.drop('Name', axis = 1)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying value of K to use for K-Means Clustering using elbow technique\n",
    "def find_k(features):\n",
    "    errors = []\n",
    "    # Itering over possible values of K\n",
    "    for k in range(1,51):\n",
    "        model = KMeans(n_clusters = k)\n",
    "        model.fit(features)\n",
    "        errors.append(sum(np.min(cdist(features, model.cluster_centers_, 'euclidean'), axis = 1)))\n",
    "\n",
    "    # Plot the graph and Identify elbow\n",
    "    with plt.style.context(['classic','ggplot']):\n",
    "        plt.figure(figsize = (10,6))\n",
    "        plt.plot(errors)\n",
    "        plt.xlabel('Clusters')\n",
    "        plt.ylabel('Errors')\n",
    "        plt.title('Elbow technique')\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copy of features DataFrame where symbol is the index\n",
    "copy_features = features.copy()\n",
    "copy_features = copy_features.reindex(index = copy_features['Symbol'], columns = copy_features.columns)\n",
    "\n",
    "# Adding data back into the Dataframe after resetting the index\n",
    "copy_features['P/E'] = features['P/E'].values\n",
    "copy_features['EPS'] = features['EPS'].values\n",
    "copy_features['MarketCap'] = features['MarketCap'].values\n",
    "copy_features = copy_features.drop('Symbol', axis = 1)\n",
    "copy_features.head()\n",
    "\n",
    "# See if there are any missing values\n",
    "copy_features.isnull().sum()\n",
    "\n",
    "# Use function to see graph of KMeans Clustering Elbow technique, While filling missing values with Zero\n",
    "find_k(copy_features.fillna(0))\n",
    "\n",
    "# K = 15 is the value I will be using to look for tradable relationships\n",
    "k_means = KMeans(n_clusters = 15, random_state = 101)\n",
    "k_means.fit(copy_features.fillna(0))\n",
    "\n",
    "# Checking the labels of the clusetrs\n",
    "copy_features['Cluster'] = k_means.labels_\n",
    "copy_features.head()\n",
    "copy_features.tail()\n",
    "\n",
    "# Create Dataframe\n",
    "clusters = pd.DataFrame()\n",
    "# Group Clusters together that are greater than 1 \n",
    "clusters = pd.concat(i for clusters, i in copy_features.groupby(copy_features['Cluster']) if len(i) > 1)\n",
    "clusters.head()\n",
    "clusters.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to identify each possible pairs \n",
    "def create_pairs(list_of_symbols):\n",
    "    pairs = []\n",
    "    # intialize placeholders for the symbols in each pair\n",
    "    x = 0\n",
    "    y = 0\n",
    "    for count, symbol in enumerate(list_of_symbols):\n",
    "        for nxcount, nxsymbol in enumerate(list_of_symbols):\n",
    "            x = symbol\n",
    "            y = nxsymbol\n",
    "            if x != y:\n",
    "                pairs.append([x,y])\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary Symbol list \n",
    "symbol_list_of_five = ['ADBE','AET','AIG','ANTM','AMAT']\n",
    "\n",
    "\n",
    "# Function to create list of grouped clusters\n",
    "def symbol_list(x):\n",
    "    list_of_symbols = []\n",
    "    for i in range(0, len(clusters)):\n",
    "        if clusters['Cluster'][i] == x:\n",
    "            symbol = clusters.index[i]\n",
    "            list_of_symbols.append(symbol)\n",
    "    return list_of_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_symbols = symbol_list(0)\n",
    "all_pairs = create_pairs(symbol_list_of_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function to parse the training and testing data from one another\n",
    "# over the period January 4th 2018 - June 12th 2018\n",
    "def parse_data(data, symbol_list, start, end):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : This is the dictionary we created that holds Dataframes\n",
    "    symbol_list : List of symbols; only 5 for now: NEED DATA FOR STOCKS IN THE S&P 500\n",
    "    start : The begining part of the training data\n",
    "    end : The ending part of the training data\n",
    "\n",
    "    Returns The training dataframe \n",
    "    -------\n",
    "    '''\n",
    "  # intialiaze the training dataframe\n",
    "    X_train = pd.DataFrame()\n",
    "  # Itering over the data\n",
    "    for count, symbol in enumerate(symbol_list):\n",
    "        # Making a copy of data for each of the symbols\n",
    "        copy = data[symbol].copy()\n",
    "        # Reindexing the copies\n",
    "        copy = copy.reindex(index = copy['Date'], columns = copy.columns)\n",
    "        # Restoring the data of the close column to the copies\n",
    "        copy[' Close'] = data[symbol][' Close'].values\n",
    "        # Parsing out the data for the training data\n",
    "        copy = copy.loc[start:end][' Close']\n",
    "        X_train[str(symbol)] = copy.values\n",
    "    return X_train\n",
    "\n",
    "X_train = parse_data(data, symbol_list_of_five, '2018/01/04', '2018/04/30')\n",
    "\n",
    "def cointegrated(all_pairs, X_train):\n",
    "    # creating a list to hold cointegrated pairs\n",
    "    cointegrated = []\n",
    "    # iterate over each pair in possible pairs list; pair is a list of our 2 stock symbols\n",
    "    for count, pair in enumerate(all_pairs):\n",
    "        # getting data for each stock in pair from training_df\n",
    "        ols = linregress(X_train[str(pair[1])], X_train[str(pair[0])]) #note scipy's linregress takes in Y then X\n",
    "        # storing slope or hedge ratio in variable\n",
    "        slope = ols[0]\n",
    "        # creating spread\n",
    "        spread = X_train[str(pair[1])] - (slope * X_train[str(pair[0])])\n",
    "        # testing spread for cointegration\n",
    "        cadf = adfuller(spread,1)\n",
    "        # checking to see if spread is cointegrated, if so then store pair in cointegrated list\n",
    "        if cadf[0] < cadf[4]['1%']:\n",
    "            print('Pair Cointegrated at 99% Confidence Interval')\n",
    "            # appending the X and Y of pair\n",
    "            cointegrated.append([pair[0],pair[1]])\n",
    "        elif cadf[0] < cadf[4]['5%']:\n",
    "            print('Pair Cointegrated at 95% Confidence Interval')\n",
    "            # appending the X and Y of pair\n",
    "            cointegrated.append([pair[0],pair[1]])\n",
    "        elif cadf[0] < cadf[4]['10%']:\n",
    "            print('Pair Cointegrated at 90% Confidence Interval')\n",
    "            cointegrated.append(pair[0],pair[1])\n",
    "        else:\n",
    "            print('Pair Not Cointegrated ')\n",
    "\n",
    "    return cointegrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of cointergrated pairs of assets\n",
    "cointegrated_first5_0 = cointegrated(all_pairs, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the amount of stocks within each cluster\n",
    "total_symbol_in_cluster = clusters.groupby(['Cluster']).size()\n",
    "\n",
    "copy_adbe = adbe.copy()\n",
    "copy_aet = aet.copy()\n",
    "copy_antm = antm.copy()\n",
    "\n",
    "copy_adbe = copy_adbe.reindex(index = copy_adbe['Date'], columns = copy_adbe.columns)\n",
    "copy_aet = copy_aet.reindex(index = copy_aet['Date'], columns = copy_aet.columns)\n",
    "copy_antm = copy_antm.reindex(index = copy_antm['Date'], columns = copy_antm.columns)\n",
    "\n",
    "copy_adbe = copy_adbe.drop('Date', axis=1)\n",
    "copy_aet = copy_aet.drop('Date', axis=1)\n",
    "copy_antm = copy_antm.drop('Date', axis=1)\n",
    "\n",
    "copy_adbe[[' Time',' Open',' High',' Low',' Close',' Volume',' NumberOfTrades',' BidVolume',' AskVolume']] = adbe[[' Time',' Open',' High',' Low',' Close',' Volume',' NumberOfTrades',' BidVolume',' AskVolume']].values\n",
    "copy_aet[[' Time',' Open',' High',' Low',' Close',' Volume',' NumberOfTrades',' BidVolume',' AskVolume']] = aet[[' Time',' Open',' High',' Low',' Close',' Volume',' NumberOfTrades',' BidVolume',' AskVolume']].values\n",
    "copy_antm[[' Time',' Open',' High',' Low',' Close',' Volume',' NumberOfTrades',' BidVolume',' AskVolume']] = antm[[' Time',' Open',' High',' Low',' Close',' Volume',' NumberOfTrades',' BidVolume',' AskVolume']].values\n",
    "\n",
    "adbe_test = copy_adbe.loc['2018/05/01':]\n",
    "aet_test = copy_aet.loc['2018/05/01':]\n",
    "antm_test = copy_antm.loc['2018/05/01':]\n",
    "\n",
    "X_test_adbe = np.array(adbe_test[' Close'])\n",
    "X_test_aet = np.array(aet_test[' Close'])\n",
    "X_test_antm = np.array(antm_test[' Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class statarbi(object):\n",
    "    def __init__(self, df1, df2, ma, floor, ceiling, beta_lookback, start, end, exit_zscore = 0):\n",
    "        # Setting the attributes\n",
    "        self.df1 = df1 # Array of the prices for X\n",
    "        self.df2 = df2 # Array of the prices for Y\n",
    "        self.ma = ma # The lookback period\n",
    "        self.floor = floor # The Threshold to buy for the z-score\n",
    "        self.ceiling = ceiling # The threshold to sell for the z-score \n",
    "        self.Close = 'Close Long' # Used as a close signal for longs\n",
    "        self.Cover = 'Cover Short' # Used as a close signal for shorts\n",
    "        self.exit_zscore = exit_zscore\n",
    "        self.beta_lookback = beta_lookback # The lookback for the hedge ratio\n",
    "        self.start = start # Begining of the test period\n",
    "        self.end = end # End of the test period \n",
    "    \n",
    "    def spread(self):\n",
    "        # Create new Dataframe\n",
    "        self.df = pd.DataFrame(index = range(0, len(self.df1)))\n",
    "        self.df['X'] = self.df1\n",
    "        self.df['Y'] = self.df2\n",
    "        \n",
    "        # Calculate the beta of the pairs\n",
    "        ols = linregress(self.df['Y'], self.df['X'])\n",
    "        self.df['Beta'] = ols[0]\n",
    "        # Calculate the spread \n",
    "        self.df['Spread'] = self.df['Y'] - (self.df['Beta'].rolling(window = self.beta_lookback).mean() * self.df['X'])\n",
    "        return self.df.head()\n",
    "\n",
    "    def signal_generation(self):\n",
    "        # Creating z-score\n",
    "        self.df['Z-Score'] = (self.df['Spread'] - self.df['Spread'].rolling(window = self.ma).mean()) / self.df['Spread'].rolling(window = self.ma).std()\n",
    "        self.df['Prior Z-score'] = self.df['Z-Score'].shift(1)\n",
    "        # Creating Buy and Sell signals where to long, short and exit\n",
    "        self.df['Longs'] = (self.df['Z-Score'] <= self.floor) * 1.0 # Buy the spread\n",
    "        self.df['Shorts'] = (self.df['Z-Score'] >= self.ceiling) * 1.0 # Short the spread\n",
    "        self.df['Exit'] = (self.df['Z-Score'] <= self.exit_zscore) * 1.0\n",
    "        # track positions with for loop\n",
    "        self.df['Long Market'] = 0.0\n",
    "        self.df['Short Market'] = 0.0 \n",
    "        # Setting variables to track whether or to be long while iterating\n",
    "        self.long_market = 0 \n",
    "        self.short_market = 0 \n",
    "        # Determing when to trade\n",
    "        for i, value in enumerate(self.df.iterrows()):\n",
    "            if value[1]['Longs'] == 1.0:\n",
    "                self.long_market = 1\n",
    "            elif value[1]['Shorts'] == 1.0:\n",
    "                self.short_market = 1\n",
    "            elif value[1]['Exit'] == 1.0:\n",
    "                self.long_market = 0\n",
    "                self.short_market = 0\n",
    "            self.df.iloc[i]['Long Market'] = self.long_market\n",
    "            self.df.iloc[i]['Short Market'] = self.short_market\n",
    "        return self.df.head()\n",
    "    \n",
    "    def returns(self, allocation, pair_number):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        allocation : The amount of Capital for each pair\n",
    "        pair_number : String to annotate the plots\n",
    "        '''\n",
    "        self.allocation = allocation\n",
    "        self.pair = pair_number\n",
    "        \n",
    "        self.portfolio = pd.DataFrame(index = self.df.index)\n",
    "        self.portfolio['Positions'] = self.df['Long Market'] - self.df['Short Market']\n",
    "        self.portfolio['X'] =- 1.0 * self.df['X'] * self.portfolio['Positions']\n",
    "        self.portfolio['Y'] = self.df['Y'] * self.portfolio['Positions']\n",
    "        self.portfolio['Total'] = self.portfolio['X'] + self.portfolio['Y'] \n",
    "        # Creating a stream of returns\n",
    "        self.portfolio['Returns'] = self.portfolio['Total'].pct_change()\n",
    "        self.portfolio['Returns'] = self.portfolio['Returns'].fillna(0.0)\n",
    "        self.portfolio['Returns'] = self.portfolio['Returns'].replace([np.inf, -np.inf], 0.0)\n",
    "        self.portfolio['Returns'] = self.portfolio['Returns'].replace(-1.0, 0.0)\n",
    "        # Calculating the Metrics\n",
    "        self.mu = (self.portfolio['Returns'].mean())\n",
    "        self.sigma = (self.portfolio['Returns'].std())\n",
    "        self.portfolio['Win'] = np.where(self.portfolio['Returns'] > 0, 1, 0)\n",
    "        self.portfolio['Loss'] = np.where(self.portfolio['Returns'] < 0, 1 ,0)\n",
    "        self.wins = self.portfolio['Win'].sum()\n",
    "        self.losses = self.portfolio['Loss'].sum()\n",
    "        self.tot_trades = self.wins + self.losses\n",
    "        # Calculating the Sharpe ratio with an interest rate of 0.75  \n",
    "        interest_rate_assumption = 0.75 # Risk free Rate\n",
    "        self.sharpe = (self.mu - interest_rate_assumption) / self.sigma\n",
    "        # win loss ration\n",
    "        self.win_loss = (self.wins / self.losses)\n",
    "        self.prob_win = (self.wins / self.tot_trades)\n",
    "        self.prob_loss = (self.losses / self.tot_trades)\n",
    "        self.avg_return_win = (self.portfolio['Returns'] > 0).mean()\n",
    "        self.avg_return_loss = (self.portfolio['Returns'] < 0).mean()\n",
    "        # Calculating the Payout ratio\n",
    "        self.payout_ratio=(self.avg_return_win/self.avg_return_loss)\n",
    "        # Creating the Equity Curve\n",
    "        self.portfolio['Returns'] = (self.portfolio['Returns'] + 1.0).cumprod()\n",
    "        self.portfolio['Trade Returns'] = (self.portfolio['Total'].pct_change())\n",
    "        self.portfolio['Portfolio Value'] = (self.allocation * self.portfolio['Returns'])\n",
    "        self.portfolio['Portfolio Returns'] = self.portfolio['Portfolio Value'].pct_change()\n",
    "        self.portfolio['Initial Value'] = self.allocation\n",
    "        \n",
    "        with plt.style.context(['ggplot', 'seaborn-paper']):\n",
    "        # Plotting Portfolio Value\n",
    "            plt.plot(self.portfolio['Portfolio Value'])\n",
    "            plt.plot(self.portfolio['Initial Value'])\n",
    "            plt.title('%s Strategy Return' %(self.pair))\n",
    "            plt.legend(loc = 0)\n",
    "            plt.show()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADBE & ANTM statarbi \n",
    "adbe_antm = statarbi(X_test_adbe, X_test_antm, 17, -2, 2, 17, adbe_test.iloc[0], adbe_test.iloc[0])\n",
    "adbe_antm.spread()\n",
    "adbe_antm.signal_generation()\n",
    "adbe_antm.returns(30000, 'ADBE_ANTM')\n",
    "\n",
    "antm_aet = statarbi(X_test_antm, X_test_aet, 6, -2, 2, 6, antm_test.iloc[0], antm_test.iloc[-1])\n",
    "antm_aet.spread()\n",
    "antm_aet.signal_generation()\n",
    "antm_aet.returns(30000,'ANTM_AET')\n",
    "\n",
    "aet_antm = statarbi(X_test_aet, X_test_antm, 12, -2, 2, 12, aet_test.iloc[0], aet_test.iloc[-1])\n",
    "aet_antm.spread()\n",
    "aet_antm.signal_generation()\n",
    "aet_antm.returns(30000,'AET_ANTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame of Equally weighted Porfolio \n",
    "equal = pd.DataFrame()\n",
    "equal['ADBE_ANTM'] = adbe_antm.portfolio['Portfolio Value']\n",
    "equal['ANTM_AET'] = antm_aet.portfolio['Portfolio Value']\n",
    "equal['AET_ANTM'] = aet_antm.portfolio['Portfolio Value']\n",
    "equal['Cash'] = 10000\n",
    "equal['Total Portfolio Value'] = equal['ADBE_ANTM'] + equal['ANTM_AET'] + equal['AET_ANTM'] + equal['Cash']\n",
    "\n",
    "# Returns Column\n",
    "equal['Returns'] = np.log(equal['Total Portfolio Value'] / equal['Total Portfolio Value'].shift(1))\n",
    "# Mean, sigma and Sharpe\n",
    "equal_mu = equal['Returns'].mean()\n",
    "equal_sigma = equal['Returns'].std()\n",
    "# In as of December 2017, the fed funds rate was 1.5%. We'll use this as our interest rate assumption. \n",
    "rate = 0.015\n",
    "equal_sharpe = round((equal_mu - rate) / equal_sigma, 2)\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.plot(equal['Total Portfolio Value'])\n",
    "plt.title('Equally Weighted Portfolio Equity Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Efficient Frontier \n",
    "mu_adbe_antm = adbe_antm.mu\n",
    "sigma_adbe_antm = adbe_antm.sigma\n",
    "mu_aet_antm = aet_antm.mu\n",
    "sigma_aet_antm = aet_antm.sigma\n",
    "mu_antm_aet = antm_aet.mu\n",
    "sigma_antm_aet = antm_aet.sigma\n",
    "\n",
    "returns = np.log(equal[['ADBE_ANTM', 'ANTM_AET', 'AET_ANTM']] / equal[['ADBE_ANTM', 'ANTM_AET', 'AET_ANTM']].shift(1))\n",
    "\n",
    "avg_returns_ann = returns.mean() * 252\n",
    "covariance = returns.cov() * 252\n",
    "\n",
    "weights = np.random.random(len(returns.columns))\n",
    "weights /= np.sum(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficient_frontier(returns, rate = 0.015):\n",
    "    # Create lists with returns, variance and sharpe ratios\n",
    "    p_returns = []\n",
    "    p_volatility = []\n",
    "    p_sharpe = []\n",
    "    \n",
    "    for i in range(500):\n",
    "        # assign weights\n",
    "        weights = np.random.random(len(returns.columns))\n",
    "        weights /= np.sum(weights)\n",
    "        # Getting returns\n",
    "        current_return = np.sum(returns.mean() * weights) * 252\n",
    "        p_returns = np.append(p_returns, current_return)\n",
    "        # Getting variances\n",
    "        variance = np.dot(weights, np.dot(returns.cov() * 252 , weights))\n",
    "        # Volatility\n",
    "        volatility = np.sqrt(variance)\n",
    "        p_volatility = np.append(p_volatility, volatility)\n",
    "        # Sharpe\n",
    "        ratio = (current_return - rate)/volatility\n",
    "        p_sharpe = np.append(p_sharpe, ratio)\n",
    "        \n",
    "        p_returns = np.array(p_returns)\n",
    "        p_volatility = np.array(p_volatility)\n",
    "        p_sharpe = np.array(p_sharpe)\n",
    "        # plot to find efficient returns\n",
    "        plt.figure(figsize = (10,6))\n",
    "        plt.scatter(p_volatility, p_returns, c = p_sharpe, marker = 'o')\n",
    "        plt.xlabel('Expected Volatility')\n",
    "        plt.ylabel('Efficient Frontier')\n",
    "        plt.colorbar(label = 'Sharpe Ratio')\n",
    "        plt.show()\n",
    "        \n",
    "    return\n",
    "\n",
    "efficient_frontier(returns.fillna(0))\n",
    "\n",
    "def stats(weights, rate = 0.015):\n",
    "    weights = np.array(weights)\n",
    "    p_returns = np.sum(returns.mean()*weights)*252\n",
    "    p_volatility = np.sqrt(np.dot(weights.T, np.dot(returns.cov()*252, weights)))\n",
    "    p_sharpe = (p_returns - rate) / p_volatility\n",
    "\n",
    "    return np.array([p_returns,p_volatility,p_sharpe])   \n",
    "\n",
    "stats(weights)\n",
    "# function for optimization\n",
    "def minimize(weights):\n",
    "    return -stats(weights)[2]\n",
    "\n",
    "minimize(weights)\n",
    "\n",
    "# Finding the optimal weights\n",
    "def optimal_weights(weights):\n",
    "    # variables for optimization\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bounds = tuple((0,1) for x in range(len(returns.columns)))\n",
    "    starting_weights = len(returns.columns) * [1 / len(returns.columns)]\n",
    "    most_optimal = sco.minimize(minimize, starting_weights, method='SLSQP', bounds = bounds, constraints = constraints)\n",
    "    best_weights = most_optimal['x'].round(3)\n",
    "    return best_weights, print('Weights:',best_weights)\n",
    "\n",
    "optimal_weights = optimal_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal weights is 0 0 1 threfore 100% weight goes to aet_antm\n",
    "allocation =  90000\n",
    "aet_antm_allocation = round(allocation * optimal_weights[0][2], 2)\n",
    "\n",
    "aet_antm_2 = statarbi(X_test_aet, X_test_antm, 12, -2, 2, 12, aet_test.iloc[0], aet_test.iloc[-1])\n",
    "aet_antm_2.spread()\n",
    "aet_antm_2.signal_generation()\n",
    "aet_antm_2.returns(aet_antm_allocation,'AET & ANTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Efficient Frontier portfolio\n",
    "p_efficient_frontier = pd.DataFrame()\n",
    "p_efficient_frontier['AET_ANTM'] = aet_antm_2.portfolio['Portfolio Value']\n",
    "p_efficient_frontier['Cash'] = 10000\n",
    "p_efficient_frontier['Total Portfolio Value'] = p_efficient_frontier['AET_ANTM'] + p_efficient_frontier['Cash']\n",
    "# adding returns to the Dataframe\n",
    "p_efficient_frontier['Returns'] = np.log(p_efficient_frontier['Total Portfolio Value'] / p_efficient_frontier['Total Portfolio Value'].shift(1))\n",
    "\n",
    "p_efficient_frontier_mu = p_efficient_frontier['Returns'].mean()\n",
    "p_efficient_frontier_sigma = p_efficient_frontier['Returns'].std()\n",
    "#recall that we initialized our interest assumption earlier\n",
    "p_efficient_frontier_sharpe = (p_efficient_frontier_mu - rate) / p_efficient_frontier_sigma\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(p_efficient_frontier['Total Portfolio Value'])\n",
    "plt.title('Efficient Frontier Portfolio Equity Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adbe_antm_historical = statarbi(X_train['ADBE'], X_train['ANTM'], 17, -2, 2, 17, adbe_test.iloc[0], adbe_test.iloc[-1])\n",
    "adbe_antm_historical.spread()\n",
    "adbe_antm_historical.signal_generation()\n",
    "#notice that we are equally weighing our strategy\n",
    "adbe_antm_historical.returns(30000,'ADBE_ANTM_3 Over Training Period')\n",
    "adbe_antm_historical_rets = adbe_antm_historical.portfolio['Returns']\n",
    "\n",
    "antm_aet_historical = statarbi(X_train['ANTM'], X_train['AET'], 6, -2, 2, 6, antm_test.iloc[0], antm_test.iloc[-1])\n",
    "antm_aet_historical.spread()\n",
    "antm_aet_historical.signal_generation()\n",
    "antm_aet_historical.returns(30000,'ANTM & AET_3 Over Hist. Train Period')\n",
    "antm_aet_historical_rets = antm_aet_historical.portfolio['Returns']\n",
    "\n",
    "aet_antm_historical = statarbi(X_train['AET'], X_train['ANTM'], 12, -2, 2, 12, antm_test.iloc[0], antm_test.iloc[-1])\n",
    "aet_antm_historical.spread()\n",
    "aet_antm_historical.signal_generation()\n",
    "aet_antm_historical.returns(30000,'AET & ANTM_3 Over Hist. Train Period')\n",
    "aet_antm_historical_rets = aet_antm_historical.portfolio['Returns']\n",
    "\n",
    "train_adbe_antm, test_adbe_antm = train_test_split(adbe_antm_historical_rets, test_size = 0.33)\n",
    "train_antm_aet, test_antm_aet = train_test_split(adbe_antm_historical_rets, test_size = 0.33)\n",
    "train_aet_antm, test_aet_antm = train_test_split(adbe_antm_historical_rets, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM_randomforests(object):\n",
    "    def __init__(self, historical_rets_train, historical_rets_test, base_portfolio_rets, gmm_components, df, base_portfolio_df, internal_test_start, internal_test_end):\n",
    "        '''\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        base_portfolio_rets : this is our figurative live data; ie returns; 5/01/18-6/12/18 from either\n",
    "            Equally Weighted or Efficient Frontier Portfolios dependent upon implementation\n",
    "            of Bottom Up or Stereoscopic Portfolio Optimization (SPO) Framework.\n",
    "            \n",
    "            ex. data over 01/04/18-04/30/18\n",
    "          \n",
    "            we would first split this 80/20 the 80% is our training set the 20% is our testing set\n",
    "          \n",
    "            we would then do another split on our training set created above this is so that \n",
    "            if we can better understand the historical regimes and recalibrate our models if \n",
    "            necessary before actually predicting our 5/1/18-6/12/18 testing set.\n",
    "          \n",
    "            in this ex. our gmm_training_train is 80% of the period 01/04/18-4/30/18\n",
    "            our gmm_training_test is 20% of the period 01/04/18-4/30/18 and our\n",
    "            gmm_test_actual is 05/01/18-6/12/18\n",
    "            \n",
    "        gmm_components : type:int; for number of components for GMM\n",
    "        \n",
    "        df : The entire dataframe containing prior trading history; the dataframe from either Equally Weighted or\n",
    "            Efficient Frontier Portfolios; Our Random Forests Implementation will take this dataframe created by\n",
    "            our statarb class(i.e. from the prior portfolios) and add our features to it. It will then use these\n",
    "            features to predict the regimes of our test period. Recall that our Equally Weighted and Efficient\n",
    "            Frontier Portfolios were constructed over our assessment period of 5/1/18 to 6/12/18. We will then\n",
    "            be able to store our predictions in a varible for our test period. These predictions will be passed\n",
    "            into a new statarb object as a parameter and be used to create the Bottom Up and SPO Framework Portfolios.\n",
    "        \n",
    "        base_portfolio_df : (i.e.adbe_antm.df,etc) Note: for the Bottom Up Implementation this df would be the Equally Weighted df but for the\n",
    "            SPO Framework df this would be the df from the Efficient Frontier implementation\n",
    "            \n",
    "        internal_test_start : type: int; this is the testing period for the total training period; in the example,\n",
    "            this is the assessment period of 05/01/18-06/12/18; start thus is len(strategy_object)*.80\n",
    "            \n",
    "        internal_test_end : type:int; this is the end of the assessment period; ie. the 20% testing split\n",
    "            of the broader split...this value is -len(strategy_object)*.20...Note this value is\n",
    "            is negative because we want the last 20% of the data\n",
    "\n",
    "        -------\n",
    "        \n",
    "        '''\n",
    "        self.historical_rets_train = historical_rets_train\n",
    "        self.historical_rets_test = historical_rets_test\n",
    "        self.base_portfolio_rets = base_portfolio_rets\n",
    "        self.gmm_components = gmm_components\n",
    "        self.max_iter = 300\n",
    "        self.random_state = 0\n",
    "        self.df = df\n",
    "        #self.total_training_start=total_training_start\n",
    "        #self.total_training_end=total_training_end\n",
    "        self.base_portfolio_df = base_portfolio_df\n",
    "        self.internal_test_start = internal_test_start\n",
    "        self.internal_test_end = internal_test_end\n",
    "        self.volatility = self.historical_rets_train.rolling(window = 5).std()\n",
    "        self.negative_volatility = np.where(self.historical_rets_train < 0 , self.historical_rets_train.rolling(window = 5).std(), 0)\n",
    "        \n",
    "    def make_GMM(self):\n",
    "        model_kwds = dict(n_components = self.gmm_components, max_iter = self.max_iter, n_init = 100, random_state = 1)\n",
    "        gmm = GM(**model_kwds)\n",
    "        return gmm\n",
    "    \n",
    "    def analyze_historical_regimes(self):\n",
    "        # Create the Guassian mixture mdoel\n",
    "        self.gmm = self.make_GMM()\n",
    "        # instantiating the Xtrain as the gmm_training_train; (the 80% of total training period)\n",
    "        self.gmm_Xtrain = np.array(self.historical_rets_train).reshape(-1, 1)\n",
    "        # Fitting the GMM on the Training Set(note this is the internal training set within the broader training set)\n",
    "        self.gmm.fit(self.gmm_Xtrain.astype(int))\n",
    "        #Making predictions on the historical period; ie. the gmm_training_train\n",
    "        self.gmm_historical_predictions = self.gmm.predict(self.gmm_Xtrain.astype(int))\n",
    "        #Making Predictions on the gmm_training_test (i.e. the 20% of total training period;)\n",
    "        self.gmm_Xtest = np.array(self.historical_rets_test).reshape(-1,1)\n",
    "        self.gmm_training_test_predictions = self.gmm.predict(self.gmm_Xtest.astype(int))\n",
    "        #Fitting the Model on ACTUAL data we want to Predict Regimes For\n",
    "        self.gmm_Actual = np.array(self.base_portfolio_rets).reshape(-1,1)\n",
    "        self.base_portfolio_predictions = self.gmm.predict(self.gmm_Actual)\n",
    "        return \n",
    "    \n",
    "    def historical_regime_returns_volatility(self, plotTitle):\n",
    "        self.plotTitle = plotTitle\n",
    "        data = pd.DataFrame({'Volatility' : self.volatility, 'Regime': self.gmm_historical_predictions, 'Returns': self.historical_rets_train})\n",
    "\n",
    "        with plt.style.context(['classic','seaborn-paper']):\n",
    "            fig,ax = plt.subplots(figsize = (15,10), nrows = 1, ncols = 2)\n",
    "            \n",
    "        left = 0.125 # the left side of the subplots of the figure\n",
    "        right = 0.9 # the right side of the subplots of the figure\n",
    "        bottom = .125 # the bottom of the subplots of the figure\n",
    "        top = 0.9 # the top of the subplots of the figure\n",
    "        wspace = .5 # the amount of width reserved for blank space between subplots\n",
    "        hspace = 1.1 # the amount of height reserved for white space between subplots \n",
    "        \n",
    "        # function that adjusts subplots using the above paramters\n",
    "        plt.subplots_adjust(\n",
    "        left = left,\n",
    "        bottom = bottom,\n",
    "        right = right,\n",
    "        top = top,\n",
    "        wspace = wspace,\n",
    "        hspace = hspace\n",
    "        )\n",
    "        \n",
    "        plt.suptitle(self.plotTitle, y = 1, fontsize=20)\n",
    "        \n",
    "        plt.subplot(121)\n",
    "        sns.swarmplot(x = 'Regime', y = 'Volatility', data = data)#,ax=ax[0][0])\n",
    "        plt.title('Regime to Volatility')\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        sns.swarmplot(x = 'Regime', y = 'Returns', data = data)#, ax=ax[0][1])\n",
    "        plt.title('Regime to Returns')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return\n",
    "        \n",
    "    def train_random_forests(self):\n",
    "        # adding features to the Dataframe assumption is that the df is over the entire period\n",
    "        # getting vix to add as feature\n",
    "        #self.VIX = pdr.get_data_yahoo('^VIX',start=self.total_training_start,end=self.total_training_end)\n",
    "        # creating features\n",
    "        #self.df['VIX']=self.VIX['Close']\n",
    "        \n",
    "        self.df['6 X Vol'] = self.df['X'].rolling(window=6).std()\n",
    "        self.df['6 Y Vol'] = self.df['Y'].rolling(window=6).std()\n",
    "        self.df['6 Spread Vol'] = self.df['Spread'].rolling(window=6).std()\n",
    "        self.df['6 Z-Score Vol'] = self.df['Z-Score'].rolling(window=6).std()\n",
    "        \n",
    "        self.df['12 X Vol'] = self.df['X'].rolling(window=12).std()\n",
    "        self.df['12 Y Vol'] = self.df['Y'].rolling(window=12).std()\n",
    "        self.df['12 Spread Vol'] = self.df['Spread'].rolling(window=12).std()\n",
    "        self.df['12 Z-Score Vol'] = self.df['Z-Score'].rolling(window=12).std()\n",
    "        \n",
    "        self.df['15 X Vol'] = self.df['X'].rolling(window=15).std()\n",
    "        self.df['15 Y Vol'] = self.df['Y'].rolling(window=15).std()\n",
    "        self.df['15 Spread Vol'] = self.df['Spread'].rolling(window=15).std()\n",
    "        self.df['15 Z-Score Vol'] = self.df['Z-Score'].rolling(window=15).std()\n",
    "\n",
    "        #self.base_portfolio_df['VIX']=self.VIX['Close']\n",
    "        self.base_portfolio_df['6 X Vol'] = self.df['X'].rolling(window=6).std()\n",
    "        self.base_portfolio_df['6 Y Vol'] = self.df['Y'].rolling(window=6).std()\n",
    "        self.base_portfolio_df['6 Spread Vol'] = self.df['Spread'].rolling(window=6).std()\n",
    "        self.base_portfolio_df['6 Z-Score Vol'] = self.df['Z-Score'].rolling(window=6).std()\n",
    "        \n",
    "        self.base_portfolio_df['12 X Vol'] = self.df['X'].rolling(window=12).std()\n",
    "        self.base_portfolio_df['12 Y Vol'] = self.df['Y'].rolling(window=12).std()\n",
    "        self.base_portfolio_df['12 Spread Vol'] = self.df['Spread'].rolling(window=12).std()\n",
    "        self.base_portfolio_df['12 Z-Score Vol'] = self.df['Z-Score'].rolling(window=12).std()\n",
    "        \n",
    "        self.base_portfolio_df['15 X Vol'] = self.df['X'].rolling(window=15).std()\n",
    "        self.base_portfolio_df['15 Y Vol'] = self.df['Y'].rolling(window=15).std()\n",
    "        self.base_portfolio_df['15 Spread Vol'] = self.df['Spread'].rolling(window=15).std()\n",
    "        self.base_portfolio_df['15 Z-Score Vol'] = self.df['Z-Score'].rolling(window=15).std()\n",
    "\n",
    "        #replacing na values\n",
    "        self.df.fillna(0, inplace=True)\n",
    "        self.df = self.df.drop(['X','Y','Longs','Shorts','Exit','Long Market','Short Market'], axis = 1)\n",
    "        # Creating X_train for RF over the historical Period; Will train over the historical period, ie self.historical_training_start/end then predict\n",
    "        self.RF_X_train = self.df[0:4180][['6 X Vol', '6 Y Vol','6 Spread Vol','6 Z-Score Vol','12 X Vol','12 Y Vol','12 Spread Vol','12 Z-Score Vol','15 X Vol','15 Y Vol','15 Spread Vol','15 Z-Score Vol']]\n",
    "        # Removiing unnecessary columns\n",
    "        #self.RF_X_train.drop(['X','Y','Longs','Shorts','Exit','Long Market','Short Market'], inplace = True, axis = 1)\n",
    "        #setting Y_Train for the RF to the predictions of GMM over historical period\n",
    "        self.RF_Y_TRAIN = self.gmm_historical_predictions\n",
    "        self.base_portfolio_df = self.base_portfolio_df.drop(['X','Y','Longs','Shorts','Exit','Long Market','Short Market'], axis = 1)\n",
    "        self.RF_X_TEST = self.base_portfolio_df[['6 X Vol','6 Y Vol','6 Spread Vol','6 Z-Score Vol','12 X Vol','12 Y Vol','12 Spread Vol','12 Z-Score Vol','15 X Vol','15 Y Vol','15 Spread Vol','15 Z-Score Vol']]\n",
    "        #dropping unnecessary columns from train data\n",
    "        #self.RF_X_TEST.drop(['X','Y','Longs','Shorts','Exit','Long Market','Short Market'], inplace = True, axis = 1)\n",
    "        # Predictions for the x test over the internal testing period\n",
    "        self.RF_Y_TEST = self.base_portfolio_predictions #regime predictions for base portfolio\n",
    "        # Building the random forest and check accuracy\n",
    "        self.RF_Model = RF(n_estimators = 100)\n",
    "        #training the random forests model on assessment period data\n",
    "        self.RF_Model.fit(self.RF_X_train.fillna(0),self.RF_Y_TRAIN)\n",
    "        #Making predictions for base portfolio period\n",
    "        self.RF_BASE_PORTFOLIO_PREDICTIONS = self.RF_Model.predict(self.RF_X_TEST.fillna(0))\n",
    "        #Checking Precision of Predictions\n",
    "        print(confusion_matrix(self.RF_Y_TEST,self.RF_BASE_PORTFOLIO_PREDICTIONS))\n",
    "        print('\\n')\n",
    "        print(classification_report(self.RF_Y_TEST,self.RF_BASE_PORTFOLIO_PREDICTIONS))\n",
    "        \n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing GMM Random Forests method\n",
    "#passing in the 1)returns for 80% of the training period(i.e.01/04/18-04/30/18),2)returns for 20% of the training period(i.e.01/04/18-04/30/18)\n",
    "#3) Returns for actual or overall test period; (i.e. 05/01/18-06/12/18) for Equally Weighted, 4) count for GMMs,\n",
    "#5)Dataframe for Equally Weighted, 6)\n",
    "adbe_antm_gmm_rf = GMM_randomforests(train_adbe_antm, test_adbe_antm, adbe_antm.portfolio['Returns'], 15, adbe_antm_historical.df, adbe_antm.df, 1871, -468)\n",
    "adbe_antm_gmm_rf.analyze_historical_regimes()\n",
    "adbe_antm_gmm_rf.historical_regime_returns_volatility('ADBE_ANTM GMM Analysis')\n",
    "\n",
    "antm_aet_gmm_rf = GMM_randomforests(train_antm_aet, test_antm_aet, antm_aet.portfolio['Returns'], 15, antm_aet_historical.df, antm_aet.df, 1871, -468)\n",
    "antm_aet_gmm_rf.analyze_historical_regimes()\n",
    "antm_aet_gmm_rf.historical_regime_returns_volatility('ANTM AET GMM Analysis')\n",
    "\n",
    "aet_antm_gmm_rf = GMM_randomforests(train_aet_antm, test_aet_antm, aet_antm.portfolio['Returns'], 15, aet_antm_historical.df, aet_antm.df, 1871, -468)\n",
    "aet_antm_gmm_rf.analyze_historical_regimes()\n",
    "aet_antm_gmm_rf.historical_regime_returns_volatility('AET_ANTM GMM Analysis')\n",
    "\n",
    "adbe_antm_gmm_rf.train_random_forests()\n",
    "adbe_antm_regime_predictions = adbe_antm_gmm_rf.base_portfolio_predictions\n",
    "\n",
    "antm_aet_gmm_rf.train_random_forests()\n",
    "antm_aet_regime_predictions = antm_aet_gmm_rf.base_portfolio_predictions\n",
    "\n",
    "aet_antm_gmm_rf.train_random_forests()\n",
    "aet_antm_regime_predictions = aet_antm_gmm_rf.base_portfolio_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class statarb_update(object):\n",
    "#np.seterr(divide='ignore',invalid='ignore')\n",
    "\n",
    "    def __init__(self, df1, df2, ptype, ma, floor, ceiling, beta_lookback, start, end, regimePredictions, p2Objective, avoid1 = 1, target1 = 0, exit_zscore = 0):\n",
    "        #setting the attributes of the data cleaning object\n",
    "        self.df1 = df1 #the complete dataframe of X\n",
    "        self.df2 = df2 # the comlete dataframe of Y\n",
    "        self.df = pd.DataFrame(index=df1.index) #creates a new dataframe in the create_spread method\n",
    "        self.ptype = ptype #the portfolio type 1= standard implementation 2=machine learning implementation\n",
    "        self.ma = ma# the moving average period for the model\n",
    "        self.floor = floor #the buy threshold for the z-score\n",
    "        self.ceiling = ceiling #the sell threshold for the z-score\n",
    "        self.Close = 'Close Long' #used as close signal for longs\n",
    "        self.Cover = 'Cover Short' #used as close signal for shorts\n",
    "        self.exit_zscore = exit_zscore #the z-score\n",
    "        self.beta_lookback = beta_lookback #the lookback of beta for hedge ratio\n",
    "        self.start = start #the beginning of test period as a string\n",
    "        self.end = end # the end of test period as a string\n",
    "        self.regimePredictions = regimePredictions.reshape(-1,1) #the regime predictions from GMM for p2=2 implementation\n",
    "        self.avoid1 = avoid1 #the regime to avoid\n",
    "        self.target1 = target1 #the regime to target\n",
    "        self.p2Objective = p2Objective # the objective of p2 implementation; can be 'Avoid','Target',or 'None';\n",
    "        \n",
    "    #create price spread\n",
    "    def create_spread(self):\n",
    "        if self.ptype == 1:   \n",
    "            #setting the new dataframe values for x and y of the closing\n",
    "            #prices of the two dataframes passed in\n",
    "            self.df['X'] = self.df1[' Close']\n",
    "            self.df['Y'] = self.df2[' Close']\n",
    "            #calculating the beta of the pairs\n",
    "            self.ols = linregress(self.df['Y'],self.df['X'])\n",
    "            #setting the hedge ratio\n",
    "            self.df['Hedge Ratio'] = self.ols[0]\n",
    "            \n",
    "            self.df['Spread'] = self.df['Y'] - (self.df['Hedge Ratio']*self.df['X'])\n",
    "\n",
    "        if self.ptype == 2:\n",
    "            #setting the new dataframe values for x and y of the closing\n",
    "            #prices of the two dataframes passed in\n",
    "            self.df['X'] = self.df1[' Close']\n",
    "            self.df['Y'] = self.df2[' Close']\n",
    "            #calculating the beta of the pairs\n",
    "            self.ols = linregress(self.df['Y'],self.df['X'])\n",
    "            #setting the hedge ratio\n",
    "            self.df['Hedge Ratio'] = self.ols[0]\n",
    "            #creating spread\n",
    "            self.df['Spread'] = self.df['Y'] - (self.df['Hedge Ratio']*self.df['X'])\n",
    "            #creating the z-score\n",
    "            self.df['Z-Score'] = (self.df['Spread'] - self.df['Spread'].rolling(window = self.ma).mean()) / self.df['Spread'].rolling(window = self.ma).std()\n",
    "            #Creating the features columns\n",
    "            self.df['6 X Vol'] = self.df['X'].rolling(window = 6).std()\n",
    "            self.df['6 Y Vol'] = self.df['Y'].rolling(window = 6).std()\n",
    "            self.df['6 Spread Vol'] = self.df['Spread'].rolling(window = 6).std()\n",
    "            self.df['6 Z-Score Vol'] = self.df['Z-Score'].rolling(window = 6).std()\n",
    "            \n",
    "            self.df['12 X Vol'] = self.df['X'].rolling(window = 12).std()\n",
    "            self.df['12 Y Vol'] = self.df['Y'].rolling(window = 12).std()\n",
    "            self.df['12 Spread Vol'] = self.df['Spread'].rolling(window = 12).std()\n",
    "            self.df['12 Z-Score Vol'] = self.df['Z-Score'].rolling(window = 12).std()\n",
    "            \n",
    "            self.df['15 X Vol'] = self.df['X'].rolling(window = 15).std()\n",
    "            self.df['15 Y Vol'] = self.df['Y'].rolling(window = 15).std()\n",
    "            self.df['15 Spread Vol'] = self.df['Spread'].rolling(window = 15).std()\n",
    "            self.df['15 Z-Score Vol'] = self.df['Z-Score'].rolling(window = 15).std()\n",
    "            #Creating the Regime Prediction Column\n",
    "            self.df['Regime'] = 0\n",
    "            self.df['Regime'] = self.regimePredictions.astype(int)\n",
    "\n",
    "        return\n",
    "\n",
    "    def generate_signals(self):\n",
    "       # Creating z-score\n",
    "        self.df['Z-Score'] = (self.df['Spread'] - self.df['Spread'].rolling(window = self.ma).mean()) / self.df['Spread'].rolling(window = self.ma).std()\n",
    "        self.df['Prior Z-score'] = self.df['Z-Score'].shift(1)\n",
    "        # Creating Buy and Sell signals where to long, short and exit\n",
    "        self.df['Longs'] = (self.df['Z-Score'] <= self.floor) * 1.0 # Buy the spread\n",
    "        self.df['Shorts'] = (self.df['Z-Score'] >= self.ceiling) * 1.0 # Short the spread\n",
    "        self.df['Exit'] = (self.df['Z-Score'] <= self.exit_zscore) * 1.0\n",
    "        # track positions with for loop\n",
    "        self.df['Long Market'] = 0.0\n",
    "        self.df['Short Market'] = 0.0 \n",
    "        # Setting variables to track whether or to be long while iterating\n",
    "        self.long_market = 0 \n",
    "        self.short_market = 0 \n",
    "        # Determing when to trade\n",
    "        for i, value in enumerate(self.df.iterrows()):\n",
    "            if value[1]['Longs'] == 1.0:\n",
    "                self.long_market = 1\n",
    "            elif value[1]['Shorts'] == 1.0:\n",
    "                self.short_market = 1\n",
    "            elif value[1]['Exit'] == 1.0:\n",
    "                self.long_market = 0\n",
    "                self.short_market = 0\n",
    "            self.df.iloc[i]['Long Market'] = self.long_market\n",
    "            self.df.iloc[i]['Short Market'] = self.short_market\n",
    "    \n",
    "        if self.ptype == 2:\n",
    "            self.df['Longs'] = (self.df['Z-Score'] <= self.floor)*1.0 #buy the spread\n",
    "            self.df['Shorts'] = (self.df['Z-Score'] >= self.ceiling)*1.0 #short the spread\n",
    "            self.df['Exit']=(self.df['Z-Score'] <= self.exit_zscore)*1.0\n",
    "            #tracking positions via for loop implementation\n",
    "            self.df['Long Market'] = 0.0\n",
    "            self.df['Short Market'] = 0.0\n",
    "            #Setting Variables to track whether or not to be long while iterating over df\n",
    "            self.long_market = 0\n",
    "            self.short_market = 0\n",
    "            #Determining when to trade\n",
    "            for i, value in enumerate(self.df.iterrows()):\n",
    "                if self.p2Objective == 'Avoid':\n",
    "                    if value[1]['Regime'] != self.avoid1:\n",
    "                        #Calculate longs\n",
    "                        if value[1]['Longs'] == 1.0:\n",
    "                            self.long_market = 1\n",
    "                        elif value[1]['Shorts'] == 1.0:\n",
    "                            self.short_market = 1\n",
    "                        elif value[1]['Exit'] == 1.0:\n",
    "                            self.long_market = 0\n",
    "                            self.short_market = 0\n",
    "                self.df.iloc[i]['Long Market'] = value[1]['Longs']#self.long_market\n",
    "                self.df.iloc[i]['Short Market'] = value[1]['Shorts']#self.short_market\n",
    "                \n",
    "                if self.p2Objective == 'Target':\n",
    "                    if value[1]['Regime'] == self.target1:\n",
    "                        #Calculate longs\n",
    "                        if value[1]['Longs'] == 1.0:\n",
    "                            self.long_market = 1\n",
    "                        elif value[1]['Shorts'] == 1.0:\n",
    "                            self.short_market = 1\n",
    "                        elif value[1]['Exit'] == 1.0:\n",
    "                            self.long_market = 0\n",
    "                            self.short_market = 0\n",
    "                self.df.iloc[i]['Long Market'] = value[1]['Longs']#self.long_market\n",
    "                self.df.iloc[i]['Short Market'] = value[1]['Shorts']#self.short_market\n",
    "\n",
    "                if self.p2Objective == 'None':\n",
    "                    #Calculate longs\n",
    "                    if value[1]['Longs'] == 1.0:\n",
    "                        self.long_market = 1                     \n",
    "                        #Calculate Shorts\n",
    "                    elif value[1]['Shorts'] == 1.0:\n",
    "                        self.short_market = 1                        \n",
    "                    elif value[1]['Exit'] == 1.0:\n",
    "                        self.long_market = 0\n",
    "                        self.short_market = 0\n",
    "\n",
    "                self.df.iloc[i]['Long Market'] = value[1]['Longs']#self.long_market\n",
    "                self.df.iloc[i]['Short Market'] = value[1]['Shorts']#self.short_market\n",
    "\n",
    "        return self.df\n",
    "\n",
    "    def create_returns(self, allocation,pair_number):\n",
    "        if self.ptype==1:\n",
    "            \n",
    "            self.allocation = allocation\n",
    "            self.pair = pair_number\n",
    "            self.portfolio = pd.DataFrame(index=self.df.index)\n",
    "            self.portfolio['Positions'] = self.df['Long Market'] - self.df['Short Market']\n",
    "            self.portfolio['X'] = -1.0 * self.df['X'] * self.portfolio['Positions']\n",
    "            self.portfolio['Y'] = self.df['Y' ] * self.portfolio['Positions']\n",
    "            self.portfolio['Total'] = self.portfolio['X'] + self.portfolio['Y']\n",
    "            #creating a percentage return stream\n",
    "            self.portfolio['Returns'] = self.portfolio['Total'].pct_change()\n",
    "            self.portfolio['Returns'].fillna(0.0,inplace=True)\n",
    "            self.portfolio['Returns'].replace([np.inf,-np.inf],0.0,inplace=True)\n",
    "            self.portfolio['Returns'].replace(-1.0,0.0,inplace=True)\n",
    "            #calculating metrics\n",
    "            self.mu = (self.portfolio['Returns'].mean())\n",
    "            self.sigma = (self.portfolio['Returns'].std())\n",
    "            self.portfolio['Win'] = np.where(self.portfolio['Returns'] > 0,1,0)\n",
    "            self.portfolio['Loss'] = np.where(self.portfolio['Returns'] < 0,1,0)\n",
    "            self.wins = self.portfolio['Win'].sum()\n",
    "            self.losses = self.portfolio['Loss'].sum()\n",
    "            self.total_trades = self.wins + self.losses\n",
    "            #calculating sharpe ratio with interest rate of\n",
    "            #interest_rate_assumption=0.75\n",
    "            #self.sharp = (self.mu - interest_rate_assumption) / self.sigma\n",
    "            #win loss ratio;\n",
    "            self.win_loss_ratio = (self.wins / self.losses)\n",
    "            #probability of win\n",
    "            self.prob_of_win = (self.wins / self.total_trades)\n",
    "            #probability of loss\n",
    "            self.prob_of_loss = (self.losses / self.total_trades)\n",
    "            #average return of wins\n",
    "            self.avg_win_return = (self.portfolio['Returns'] > 0).mean()\n",
    "            #average returns of losses\n",
    "            self.avg_loss_return = (self.portfolio['Returns'] < 0).mean()\n",
    "            #calculating payout ratio\n",
    "            self.payout_ratio = (self.avg_win_return/self.avg_loss_return)\n",
    "            #calculate equity curve\n",
    "            self.portfolio['Returns'] = (self.portfolio['Returns'] + 1.0).cumprod()\n",
    "            self.portfolio['Trade Returns'] = (self.portfolio['Total'].pct_change()) #non cumulative Returns\n",
    "            self.portfolio['Portfolio Value'] = (self.allocation * self.portfolio['Returns'])\n",
    "            self.portfolio['Portfolio Returns'] = self.portfolio['Portfolio Value'].pct_change()\n",
    "            self.portfolio['Initial Value'] = self.allocation\n",
    "            \n",
    "            with plt.style.context(['ggplot','seaborn-paper']):\n",
    "                #Plotting Portfolio Value\n",
    "                plt.plot(self.portfolio['Portfolio Value'])\n",
    "                plt.plot(self.portfolio['Initial Value'])\n",
    "                plt.title('%s Strategy Returns '%(self.pair))\n",
    "                plt.legend(loc=0)\n",
    "                plt.show()\n",
    "\n",
    "        elif self.ptype==2:\n",
    "            \n",
    "            self.allocation = allocation\n",
    "            self.pair = pair_number\n",
    "            self.portfolio = pd.DataFrame(index=self.df.index)\n",
    "            self.portfolio['Positions'] =self.df['Longs'] - self.df['Shorts']\n",
    "            self.portfolio['X'] = -1.0 * self.df['X'] * self.portfolio['Positions']\n",
    "            self.portfolio['Y'] = self.df['Y' ] * self.portfolio['Positions']\n",
    "            self.portfolio['Total'] = self.portfolio['X'] + self.portfolio['Y']\n",
    "            #creating a percentage return stream\n",
    "            self.portfolio.fillna(0.0,inplace=True)\n",
    "            self.portfolio['Returns'] = self.portfolio['Total'].pct_change()\n",
    "            self.portfolio['Returns'].fillna(0.0, inplace = True)\n",
    "            self.portfolio['Returns'].replace([np.inf, -np.inf], 0.0, inplace = True)\n",
    "            self.portfolio['Returns'].replace(-1.0,0.0, inplace = True)\n",
    "            #calculating metrics\n",
    "            self.mu = (self.portfolio['Returns'].mean())\n",
    "            self.sigma = (self.portfolio['Returns'].std())\n",
    "            self.portfolio['Win'] = np.where(self.portfolio['Returns'] > 0,1,0)\n",
    "            self.portfolio['Loss'] = np.where(self.portfolio['Returns'] < 0,1,0)\n",
    "            self.wins = self.portfolio['Win'].sum()\n",
    "            self.losses = self.portfolio['Loss'].sum()\n",
    "            self.total_trades = self.wins + self.losses\n",
    "            #calculating sharpe ratio with interest rate of\n",
    "            #interest_rate_assumption=0.75\n",
    "            #self.sharp = (self.mu - interest_rate_assumption) / self.sigma\n",
    "            #win loss ratio;\n",
    "            self.win_loss_ratio = (self.wins / self.losses)\n",
    "            #probability of win\n",
    "            self.prob_of_win = (self.wins / self.total_trades)\n",
    "            #probability of loss\n",
    "            self.prob_of_loss = (self.losses / self.total_trades)\n",
    "            #average return of wins\n",
    "            self.avg_win_return = (self.portfolio['Returns'] > 0).mean()\n",
    "            #average returns of losses\n",
    "            self.avg_loss_return = (self.portfolio['Returns'] < 0).mean()\n",
    "            #calculating payout ratio\n",
    "            self.payout_ratio = (self.avg_win_return/self.avg_loss_return)\n",
    "            #calculate equity curve\n",
    "            self.portfolio['Returns'] = (self.portfolio['Returns'] + 1.0).cumprod()\n",
    "            self.portfolio['Trade Returns'] = (self.portfolio['Total'].pct_change()) #non cumulative Returns\n",
    "            self.portfolio['Portfolio Value'] = (self.allocation * self.portfolio['Returns'])\n",
    "            self.portfolio['Portfolio Returns'] = self.portfolio['Portfolio Value'].pct_change()\n",
    "            self.portfolio['Initial Value'] = self.allocation\n",
    "            \n",
    "            with plt.style.context(['ggplot','seaborn-paper']):\n",
    "                #Plotting Portfolio Value\n",
    "                plt.plot(self.portfolio['Portfolio Value'])\n",
    "                plt.plot(self.portfolio['Initial Value'])\n",
    "                plt.title('%s Strategy Returns '%(self.pair))\n",
    "                plt.legend(loc = 0)\n",
    "                plt.show()\n",
    "\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adbe_antm_bottom_up = statarb_update(adbe_test, antm_test, 2, 17,-2, 2, 17,'05/01/18','06/12/18', adbe_antm_regime_predictions,'None', avoid1 = 3, target1 = 0, exit_zscore = 0)\n",
    "#creating spread\n",
    "adbe_antm_bottom_up.create_spread()\n",
    "#generating signals\n",
    "adbe_antm_bottom_up.generate_signals()\n",
    "#getting performance\n",
    "#notice that we are passing in our equal weight amount here\n",
    "adbe_antm_bottom_up.create_returns(30000,'ADBE_ANTM Bottom Up')\n",
    "\n",
    "antm_aet_bottom_up = statarb_update(antm_test, aet_test, 2,6,-2, 2,6,'05/01/18','06/12/18',antm_aet_regime_predictions,'None',avoid1 = 0,target1 = 1, exit_zscore = 0)\n",
    "#creating spread\n",
    "antm_aet_bottom_up.create_spread()\n",
    "#generating signals\n",
    "antm_aet_bottom_up.generate_signals()\n",
    "#getting performance\n",
    "#notice that we are passing in our equal weight amount here\n",
    "antm_aet_bottom_up.create_returns(30000,'ANTM AET Bottom Up')\n",
    "\n",
    "aet_antm_bottom_up = statarb_update(aet_test, antm_test, 2, 12,-2, 2,12,'05/01/18','06/12/18',aet_antm_regime_predictions,'None',avoid1 = 1,target1 = 0, exit_zscore = 0)\n",
    "#creating spread\n",
    "aet_antm_bottom_up.create_spread()\n",
    "#generating signals\n",
    "aet_antm_bottom_up.generate_signals()\n",
    "#getting performance\n",
    "#notice that we are passing in our equal weight amount here\n",
    "aet_antm_bottom_up.create_returns(30000,'AET_ANTM Bottom Up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_up_portfolio = pd.DataFrame()\n",
    "bottom_up_portfolio['ADBE_ANTM'] = adbe_antm_bottom_up.portfolio['Portfolio Value']\n",
    "bottom_up_portfolio['AET_ANTM'] = aet_antm_bottom_up.portfolio['Portfolio Value']\n",
    "bottom_up_portfolio['ANTM_AET'] = antm_aet_bottom_up.portfolio['Portfolio Value']\n",
    "bottom_up_portfolio['Cash'] = 10000\n",
    "bottom_up_portfolio['Total Portfolio Value'] = bottom_up_portfolio['ADBE_ANTM'] + bottom_up_portfolio['ANTM_AET'] + bottom_up_portfolio['AET_ANTM'] + bottom_up_portfolio['Cash']\n",
    "\n",
    "#adding returns column to Bottom Up Dataframe\n",
    "bottom_up_portfolio['Returns'] = np.log(bottom_up_portfolio['Total Portfolio Value'] / bottom_up_portfolio['Total Portfolio Value'].shift(1))\n",
    "\n",
    "bottom_up_portfolio_mu = bottom_up_portfolio['Returns'].mean()\n",
    "bottom_up_portfolio_sigma = bottom_up_portfolio['Returns'].std()\n",
    "#recall that we initialized our interest assumption earlier\n",
    "bottom_up_portfolio_sharpe = (bottom_up_portfolio_mu-rate) / bottom_up_portfolio_sigma\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.plot(bottom_up_portfolio['Total Portfolio Value'])\n",
    "plt.title('Bottom Up Portfolio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aet_antm_spo = statarb_update(aet_test, antm_test, 1,12,-2, 2,12,'05/01/18','06/12/18',aet_antm_regime_predictions,'Avoid',avoid1=1,target1=0,exit_zscore=0)\n",
    "#creating spread\n",
    "aet_antm_spo.create_spread()\n",
    "#generating signals\n",
    "aet_antm_spo.generate_signals()\n",
    "#getting performance\n",
    "#notice that we are passing in our efficient frontier weight amount here\n",
    "aet_antm_spo.create_returns(aet_antm_allocation,'AET_ANTM SPO Framework')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spo_portfolio = pd.DataFrame()\n",
    "spo_portfolio['AET_ANTM'] = aet_antm_spo.portfolio['Portfolio Value']\n",
    "spo_portfolio['Cash']=10000\n",
    "spo_portfolio['Total Portfolio Value'] = spo_portfolio['AET_ANTM'] + spo_portfolio['Cash']\n",
    "spo_portfolio['Returns'] = np.log(spo_portfolio['Total Portfolio Value'] / spo_portfolio['Total Portfolio Value'].shift(1))\n",
    "\n",
    "spo_portfolio_mu = spo_portfolio['Returns'].mean()\n",
    "spo_portfolio_sigma = spo_portfolio['Returns'].std()\n",
    "#recall that we initialized our interest assumption earlier\n",
    "spo_portfolio_sharpe = (spo_portfolio_mu-rate)/spo_portfolio_sigma\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.plot(spo_portfolio['Total Portfolio Value'])\n",
    "plt.title('SPO Portfolio Equity Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list to hold portfolio names\n",
    "names = ['Equally Weighted','Efficient Frontier','Bottom Up','SPO Framework']\n",
    "#variable to hold column name\n",
    "column_name = 'Sharpe Ratio'\n",
    "#list to hold Sharpe Ratios\n",
    "sharpes = [equal_sharpe, p_efficient_frontier_sharpe, bottom_up_portfolio_sharpe, spo_portfolio_sharpe]\n",
    "#creating dataframe to compare Sharpe Ratios of Portfolios\n",
    "portfolio_assessment = pd.DataFrame({column_name:sharpes},index = names)\n",
    "\n",
    "#creating list to hold ending values of portfolios\n",
    "#We pass in 1 into the tail method because it represents the last index position\n",
    "portfolio_values = [equal['Total Portfolio Value'].tail(1).values.astype(int), p_efficient_frontier['Total Portfolio Value'].tail(1).values.astype(int), bottom_up_portfolio['Total Portfolio Value'].tail(1).values.astype(int),spo_portfolio['Total Portfolio Value'].tail(1).values.astype(int)]\n",
    "#creating dataframe to hold ending value of portfolios\n",
    "pd.DataFrame({'Ending Portfolio Values':portfolio_values},index=names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
